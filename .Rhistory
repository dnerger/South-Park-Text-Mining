dev.off()
tdm <- TermDocumentMatrix(corpus,control = list(weighting = function(x) weightTfIdf(x, normalize = FALSE)))
tdm <- removeSparseTerms(tdm, 0.7)
tdmMatrix <- as.matrix(tdm)
#remove connections below 15
tdmMatrix[tdmMatrix<15] <- 0
tdmMatrix[tdmMatrix>=15] <- 1
termMatrix <- tdmMatrix %*% t(tdmMatrix)
library(igraph)
# build a graph from the above matrix
g <- graph.adjacency(termMatrix, weighted=T, mode="undirected")
# remove loops
g <- simplify(g)
# set labels and degrees of vertices
V(g)$label <- V(g)$name
V(g)$degree <- degree(g)/30000
set.seed(3952)
layout1 <- layout.fruchterman.reingold(g)
pdf("term-network.pdf")
plot(g, layout=layout1)
dev.off()
tdm <- TermDocumentMatrix(corpus,control = list(weighting = function(x) weightTfIdf(x, normalize = FALSE)))
tdm <- removeSparseTerms(tdm, 0.1)
tdmMatrix <- as.matrix(tdm)
#remove connections below 15
tdmMatrix[tdmMatrix<15] <- 0
tdmMatrix[tdmMatrix>=15] <- 1
termMatrix <- tdmMatrix %*% t(tdmMatrix)
library(igraph)
# build a graph from the above matrix
g <- graph.adjacency(termMatrix, weighted=T, mode="undirected")
# remove loops
g <- simplify(g)
# set labels and degrees of vertices
V(g)$label <- V(g)$name
V(g)$degree <- degree(g)/30000
set.seed(3952)
layout1 <- layout.fruchterman.reingold(g)
pdf("term-network.pdf")
plot(g, layout=layout1)
dev.off()
tdm <- TermDocumentMatrix(corpus,control = list(weighting = function(x) weightTfIdf(x, normalize = FALSE)))
tdm <- removeSparseTerms(tdm, 0.2)
tdmMatrix <- as.matrix(tdm)
#remove connections below 15
tdmMatrix[tdmMatrix<15] <- 0
tdmMatrix[tdmMatrix>=15] <- 1
termMatrix <- tdmMatrix %*% t(tdmMatrix)
library(igraph)
# build a graph from the above matrix
g <- graph.adjacency(termMatrix, weighted=T, mode="undirected")
# remove loops
g <- simplify(g)
# set labels and degrees of vertices
V(g)$label <- V(g)$name
V(g)$degree <- degree(g)/30000
set.seed(3952)
layout1 <- layout.fruchterman.reingold(g)
pdf("term-network.pdf")
plot(g, layout=layout1)
dev.off()
tdm <- TermDocumentMatrix(corpus,control = list(weighting = function(x) weightTfIdf(x, normalize = FALSE)))
tdm <- removeSparseTerms(tdm, 0.4)
tdmMatrix <- as.matrix(tdm)
#remove connections below 15
tdmMatrix[tdmMatrix<15] <- 0
tdmMatrix[tdmMatrix>=15] <- 1
termMatrix <- tdmMatrix %*% t(tdmMatrix)
library(igraph)
# build a graph from the above matrix
g <- graph.adjacency(termMatrix, weighted=T, mode="undirected")
# remove loops
g <- simplify(g)
# set labels and degrees of vertices
V(g)$label <- V(g)$name
V(g)$degree <- degree(g)/30000
set.seed(3952)
layout1 <- layout.fruchterman.reingold(g)
pdf("term-network.pdf")
plot(g, layout=layout1)
dev.off()
tdm <- TermDocumentMatrix(corpus,control = list(weighting = function(x) weightTfIdf(x, normalize = FALSE)))
tdm <- removeSparseTerms(tdm, 0.3)
tdmMatrix <- as.matrix(tdm)
#remove connections below 15
tdmMatrix[tdmMatrix<15] <- 0
tdmMatrix[tdmMatrix>=15] <- 1
termMatrix <- tdmMatrix %*% t(tdmMatrix)
library(igraph)
# build a graph from the above matrix
g <- graph.adjacency(termMatrix, weighted=T, mode="undirected")
# remove loops
g <- simplify(g)
# set labels and degrees of vertices
V(g)$label <- V(g)$name
V(g)$degree <- degree(g)/30000
set.seed(3952)
layout1 <- layout.fruchterman.reingold(g)
pdf("term-network.pdf")
plot(g, layout=layout1)
dev.off()
tdm <- TermDocumentMatrix(corpus,control = list(weighting = function(x) weightTfIdf(x, normalize = FALSE)))
tdm <- removeSparseTerms(tdm, 0.5)
tdmMatrix <- as.matrix(tdm)
#remove connections below 15
tdmMatrix[tdmMatrix<15] <- 0
tdmMatrix[tdmMatrix>=15] <- 1
termMatrix <- tdmMatrix %*% t(tdmMatrix)
library(igraph)
# build a graph from the above matrix
g <- graph.adjacency(termMatrix, weighted=T, mode="undirected")
# remove loops
g <- simplify(g)
# set labels and degrees of vertices
V(g)$label <- V(g)$name
V(g)$degree <- degree(g)/30000
set.seed(3952)
layout1 <- layout.fruchterman.reingold(g)
pdf("term-network.pdf")
plot(g, layout=layout1)
dev.off()
tdm <- TermDocumentMatrix(corpus,control = list(weighting = function(x) weightTfIdf(x, normalize = FALSE)))
tdm <- removeSparseTerms(tdm, 0.45)
tdmMatrix <- as.matrix(tdm)
#remove connections below 15
tdmMatrix[tdmMatrix<15] <- 0
tdmMatrix[tdmMatrix>=15] <- 1
termMatrix <- tdmMatrix %*% t(tdmMatrix)
library(igraph)
# build a graph from the above matrix
g <- graph.adjacency(termMatrix, weighted=T, mode="undirected")
# remove loops
g <- simplify(g)
# set labels and degrees of vertices
V(g)$label <- V(g)$name
V(g)$degree <- degree(g)/30000
set.seed(3952)
layout1 <- layout.fruchterman.reingold(g)
pdf("term-network.pdf")
plot(g, layout=layout1)
dev.off()
tdm <- TermDocumentMatrix(corpus,control = list(weighting = function(x) weightTfIdf(x, normalize = FALSE)))
tdm <- removeSparseTerms(tdm, 0.325)
tdmMatrix <- as.matrix(tdm)
#remove connections below 15
tdmMatrix[tdmMatrix<15] <- 0
tdmMatrix[tdmMatrix>=15] <- 1
termMatrix <- tdmMatrix %*% t(tdmMatrix)
library(igraph)
# build a graph from the above matrix
g <- graph.adjacency(termMatrix, weighted=T, mode="undirected")
# remove loops
g <- simplify(g)
# set labels and degrees of vertices
V(g)$label <- V(g)$name
V(g)$degree <- degree(g)/30000
set.seed(3952)
layout1 <- layout.fruchterman.reingold(g)
pdf("term-network.pdf")
plot(g, layout=layout1)
dev.off()
tdm <- TermDocumentMatrix(corpus,control = list(weighting = function(x) weightTfIdf(x, normalize = FALSE)))
tdm <- removeSparseTerms(tdm, 0.335)
tdmMatrix <- as.matrix(tdm)
#remove connections below 15
tdmMatrix[tdmMatrix<15] <- 0
tdmMatrix[tdmMatrix>=15] <- 1
termMatrix <- tdmMatrix %*% t(tdmMatrix)
library(igraph)
# build a graph from the above matrix
g <- graph.adjacency(termMatrix, weighted=T, mode="undirected")
# remove loops
g <- simplify(g)
# set labels and degrees of vertices
V(g)$label <- V(g)$name
V(g)$degree <- degree(g)/30000
set.seed(3952)
layout1 <- layout.fruchterman.reingold(g)
pdf("term-network.pdf")
plot(g, layout=layout1)
dev.off()
tdm <- TermDocumentMatrix(corpus,control = list(weighting = function(x) weightTfIdf(x, normalize = FALSE)))
tdm <- removeSparseTerms(tdm, 0.345)
tdmMatrix <- as.matrix(tdm)
#remove connections below 15
tdmMatrix[tdmMatrix<15] <- 0
tdmMatrix[tdmMatrix>=15] <- 1
termMatrix <- tdmMatrix %*% t(tdmMatrix)
library(igraph)
# build a graph from the above matrix
g <- graph.adjacency(termMatrix, weighted=T, mode="undirected")
# remove loops
g <- simplify(g)
# set labels and degrees of vertices
V(g)$label <- V(g)$name
V(g)$degree <- degree(g)/30000
set.seed(3952)
layout1 <- layout.fruchterman.reingold(g)
pdf("term-network.pdf")
plot(g, layout=layout1)
dev.off()
tdm <- TermDocumentMatrix(corpus,control = list(weighting = function(x) weightTfIdf(x, normalize = FALSE)))
tdm <- removeSparseTerms(tdm, 0.345)
tdmMatrix <- as.matrix(tdm)
#remove connections below 15
tdmMatrix[tdmMatrix<18] <- 0
tdmMatrix[tdmMatrix>=18] <- 1
termMatrix <- tdmMatrix %*% t(tdmMatrix)
library(igraph)
# build a graph from the above matrix
g <- graph.adjacency(termMatrix, weighted=T, mode="undirected")
# remove loops
g <- simplify(g)
# set labels and degrees of vertices
V(g)$label <- V(g)$name
V(g)$degree <- degree(g)/30000
set.seed(3952)
layout1 <- layout.fruchterman.reingold(g)
pdf("term-network.pdf")
plot(g, layout=layout1)
dev.off()
tdm <- TermDocumentMatrix(corpus,control = list(weighting = function(x) weightTfIdf(x, normalize = FALSE)))
tdm <- removeSparseTerms(tdm, 0.345)
tdmMatrix <- as.matrix(tdm)
#remove connections below 15
tdmMatrix[tdmMatrix<13] <- 0
tdmMatrix[tdmMatrix>=13] <- 1
termMatrix <- tdmMatrix %*% t(tdmMatrix)
library(igraph)
# build a graph from the above matrix
g <- graph.adjacency(termMatrix, weighted=T, mode="undirected")
# remove loops
g <- simplify(g)
# set labels and degrees of vertices
V(g)$label <- V(g)$name
V(g)$degree <- degree(g)/30000
set.seed(3952)
layout1 <- layout.fruchterman.reingold(g)
pdf("term-network.pdf")
plot(g, layout=layout1)
dev.off()
tdm <- TermDocumentMatrix(corpus,control = list(weighting = function(x) weightTfIdf(x, normalize = FALSE)))
tdm <- removeSparseTerms(tdm, 0.4)
tdmMatrix <- as.matrix(tdm)
#remove connections below 10
tdmMatrix[tdmMatrix<10] <- 0
tdmMatrix[tdmMatrix>=10] <- 1
termMatrix <- tdmMatrix %*% t(tdmMatrix)
library(igraph)
# build a graph from the above matrix
g <- graph.adjacency(termMatrix, weighted=T, mode="undirected")
# remove loops
g <- simplify(g)
# set labels and degrees of vertices
V(g)$label <- V(g)$name
V(g)$degree <- degree(g)/30000
set.seed(3952)
layout1 <- layout.fruchterman.reingold(g)
pdf("term-network.pdf")
plot(g, layout=layout1)
dev.off()
directory <- "~/GitHub/South-Park-Text-Mining"
dir.create(directory, recursive = TRUE, showWarnings = FALSE)
setwd(directory)
dialogue <- read.csv("all-seasons.csv", stringsAsFactors=FALSE)
library(stringr)
library(NMF)
library(tm)
seasons <-unique(dialogue$Season)
seasons <-sort.int(as.numeric(as.character(seasons)))
by.season <- NULL;
for(g in seq_along(seasons)){
subset <- dialogue[dialogue$Season==seasons[g], ]
subset <- subset[complete.cases(subset), ]
text <- str_c(subset$Line, collapse=" ")
row <- data.frame( season=seasons[g], text=text)
by.season <- rbind(by.season, row)
}
#create corpus
myReader <- readTabular(mapping=list(content="text", id="season"))
#can exchange by.season with by.episode, delivers different results for tf-idf
corpus <- Corpus(DataframeSource(by.season), readerControl=list(reader=myReader))
#preprocessing
corpus <- tm_map(corpus,content_transformer(function(x) iconv(x, to='UTF-8', sub='byte')))
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, content_transformer(removePunctuation))
corpus <- tm_map(corpus, content_transformer(removeNumbers))
corpus <- tm_map(corpus, content_transformer(stripWhitespace))
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stemDocument, language = "english")
tdm <- TermDocumentMatrix(corpus,control = list(weighting = function(x) weightTfIdf(x, normalize = FALSE)))
tdm <- removeSparseTerms(tdm, 0.4)
nmf_overall <- nmf(as.matrix((tdm)),20,"lee", .options="t" )
nmf_overall2 <- fit(nmf_overall)
nmf_hat <- fitted(nmf_overall)
summary(nmf_hat)
base <-basis(nmf_overall)
base
coeff <- coef(nmf_overall)
coeff
algorithm(nmf_overall)
coefmap(nmf_overall, subsetRow = TRUE)
base[,1]
nmf_w <- nmf_overall2@W
nmf_h <- nmf_overall2@H
nmf_h
nmf_overall <- nmf(as.matrix((tdm)),3,"lee", .options="t" )
nmf_overall2 <- fit(nmf_overall)
nmf_hat <- fitted(nmf_overall)
summary(nmf_hat)
base <-basis(nmf_overall)
base
coeff <- coef(nmf_overall)
coeff
algorithm(nmf_overall)
coefmap(nmf_overall, subsetRow = TRUE)
base[,1]
nmf_w <- nmf_overall2@W
nmf_h <- nmf_overall2@H
nmf_h
nmf_test[,1]
coefmap(nmf_overall, subsetRow = TRUE)
coefmap(nmf_overall2)
plot(nmf_overall.multi.method)
nmf_overall.multi.method <- nmf(as.matrix((tdm)), 3, list("brunet", "lee", "ns"),
seed = 123456, .options = "t")
plot(nmf_overall.multi.method)
nmf_overall <- nmf(as.matrix((tdm)),3,"brunet", .options="t" )
nmf_overall <- nmf(as.matrix((tdm)),3,"brunet", .options="t" )
nmf_overall2 <- fit(nmf_overall)
nmf_hat <- fitted(nmf_overall)
summary(nmf_hat)
base <-basis(nmf_overall)
base
coeff <- coef(nmf_overall)
coeff
algorithm(nmf_overall)
coefmap(nmf_overall, subsetRow = TRUE)
tdm <- TermDocumentMatrix(corpus,control = list(weighting = function(x) weightTfIdf(x, normalize = FALSE)))
tdm <- removeSparseTerms(tdm, 0.99)
nmf_overall <- nmf(as.matrix((tdm)),3,"brunet", .options="t" )
nmf_overall2 <- fit(nmf_overall)
nmf_hat <- fitted(nmf_overall)
summary(nmf_hat)
base <-basis(nmf_overall)
base
coeff <- coef(nmf_overall)
coeff
algorithm(nmf_overall)
coefmap(nmf_overall, subsetRow = TRUE)
base[,1]
tdm <- TermDocumentMatrix(corpus,control = list(weighting = function(x) weightTfIdf(x, normalize = FALSE)))
nmf_overall <- nmf(as.matrix((tdm)),3,"brunet", .options="t" )
nmf_overall2 <- fit(nmf_overall)
nmf_hat <- fitted(nmf_overall)
summary(nmf_hat)
base <-basis(nmf_overall)
base
coeff <- coef(nmf_overall)
coeff
algorithm(nmf_overall)
coefmap(nmf_overall, subsetRow = TRUE)
tdm <- TermDocumentMatrix(corpus,control = list(tokenize = allTokenizer))
allTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 1, max = 1))
tdm <- TermDocumentMatrix(corpus,control = list(tokenize = allTokenizer))
library(RWeka)
allTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 1, max = 1))
tdm <- TermDocumentMatrix(corpus,control = list(tokenize = allTokenizer))
nmf_overall <- nmf(as.matrix((tdm)),3,"brunet", .options="t" )
nmf_overall2 <- fit(nmf_overall)
nmf_hat <- fitted(nmf_overall)
summary(nmf_hat)
base <-basis(nmf_overall)
base
coeff <- coef(nmf_overall)
coeff
algorithm(nmf_overall)
coefmap(nmf_overall, subsetRow = TRUE)
nmf_overall <- nmf(as.matrix((tdm)),3,"lee", .options="t" )
nmf_overall2 <- fit(nmf_overall)
nmf_hat <- fitted(nmf_overall)
summary(nmf_hat)
base <-basis(nmf_overall)
base
coeff <- coef(nmf_overall)
coeff
algorithm(nmf_overall)
coefmap(nmf_overall, subsetRow = TRUE)
tdm <- TermDocumentMatrix(corpus,control = list(tokenize = allTokenizer))
tdm <- removeSparseTerms(tdm, 0.9)
nmf_overall <- nmf(as.matrix((tdm)),3,"lee", .options="t" )
nmf_overall2 <- fit(nmf_overall)
nmf_hat <- fitted(nmf_overall)
summary(nmf_hat)
base <-basis(nmf_overall)
base
coeff <- coef(nmf_overall)
coeff
algorithm(nmf_overall)
coefmap(nmf_overall, subsetRow = TRUE)
base[,1]
mf_overall.multi.method <- nmf(as.matrix((tdm)), 3, list("brunet", "lee", "ns"),
seed = 123456, .options = "t")
nmf_overall.multi.method <- nmf(as.matrix((tdm)), 3, list("brunet", "lee", "ns"),
seed = 123456, .options = "t")
plot(nmf_overall.multi.method)
which.max(nmf_h[,241])
coefmap(nmf_overall, subsetRow = TRUE)
tdm <- TermDocumentMatrix(corpus,control = list(tokenize = allTokenizer))
tdm <- removeSparseTerms(tdm, 0.7)
nmf_overall <- nmf(as.matrix((tdm)),3,"lee", .options="t" )
nmf_overall2 <- fit(nmf_overall)
nmf_hat <- fitted(nmf_overall)
summary(nmf_hat)
base <-basis(nmf_overall)
base
coeff <- coef(nmf_overall)
coeff
algorithm(nmf_overall)
coefmap(nmf_overall, subsetRow = TRUE)
tdm <- TermDocumentMatrix(corpus,control = list(tokenize = allTokenizer))
tdm <- removeSparseTerms(tdm, 0.5)
nmf_overall <- nmf(as.matrix((tdm)),3,"lee", .options="t" )
nmf_overall2 <- fit(nmf_overall)
nmf_hat <- fitted(nmf_overall)
summary(nmf_hat)
base <-basis(nmf_overall)
base
coeff <- coef(nmf_overall)
coeff
algorithm(nmf_overall)
coefmap(nmf_overall, subsetRow = TRUE)
tdm <- TermDocumentMatrix(corpus,control = list(tokenize = allTokenizer))
tdm <- removeSparseTerms(tdm, 0.4)
nmf_overall <- nmf(as.matrix((tdm)),3,"lee", .options="t" )
nmf_overall2 <- fit(nmf_overall)
nmf_hat <- fitted(nmf_overall)
summary(nmf_hat)
base <-basis(nmf_overall)
base
coeff <- coef(nmf_overall)
coeff
algorithm(nmf_overall)
coefmap(nmf_overall, subsetRow = TRUE)
base[,1]
coefmap(nmf_overall2)
library(tm)
library(RWeka)
library(stringr)
directory <- "~/GitHub/South-Park-Text-Mining"
dir.create(directory, recursive = TRUE, showWarnings = FALSE)
setwd(directory)
# read in the data set
scripts <- read.csv("all-seasons.csv", stringsAsFactors=FALSE)
# condense to get rid of season / episode
scripts$Character <- gsub("Mrs. Garrison", "Mr. Garrison", scripts$Character) # combine Garrisons
scripts$Character <-gsub("\n", "", scripts$Character)
by.speaker <- NULL
unique(scripts$Character)
for(speaker in unique(scripts$Character)){
subset <- scripts[scripts$Character==speaker, ]
text <- str_c(subset$Text, collapse=" ")
row <- data.frame(speaker, text)
by.speaker <- rbind(by.speaker, row)
}
by.speaker[2]
# condense low-volume speakers into one to create a manageable corpus
# this keeps 27
by.speaker.big <- by.speaker[nchar(as.character(by.speaker$text)) > 5500, ]
by.speaker.big[2]
# save the rest of the text into one big speaker "All others"
kept.speakers <- unique(as.character(by.speaker.big$speaker))
other.text <- by.speaker[!(by.speaker$speaker %in% kept.speakers), ]
other.text <- str_c(other.text$text, collapse=" ")
other <- data.frame(speaker="All others", text=other.text)
# add it back in
by.speaker <- rbind(by.speaker.big, other); rm(by.speaker.big)
# create corpus
myReader <- readTabular(mapping=list(content="text", id="speaker"))
corpus <- Corpus(DataframeSource(by.speaker), readerControl=list(reader=myReader))
# pre-process text
corpus <- tm_map(corpus,content_transformer(function(x) iconv(x, to='UTF-8-MAC', sub='byte')), mc.cores=1)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, content_transformer(removePunctuation), mc.cores=1)
corpus <- tm_map(corpus, content_transformer(removeNumbers))
corpus <- tm_map(corpus, content_transformer(stripWhitespace))
corpus <- tm_map(corpus, removeWords, stopwords("english"))
# create term document matrix
options(mc.cores=1)
allTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 1, max = 3))
all.tdm <- TermDocumentMatrix(corpus, control = list(tokenize = allTokenizer))
all.tdm.nonsparse <- as.matrix(all.tdm)
# remove sparse terms
all.tdm.75 <- removeSparseTerms(all.tdm, 0.75) # 3117 / 728215
all.tdm.75nonsparse <- as.matrix(all.tdm.75)
write.csv(all.tdm.75nonsparse, "southpark_tdm_speakers.csv")
# save as a simple data frame
count.all <- data.frame(inspect(all.tdm))
count.all$word <- row.names(count.all)
write.csv(count.all, "southpark_tdm_all.csv", row.names=FALSE)
library(wordcloud)
count.all <- read.csv("southpark_tdm_speakers.csv", stringsAsFactors=FALSE)
findFreq <- function(df){
df$total <- rowSums(df[,2:22])
freqs <- df[,c(1,23)]
freqs <- freqs[order(-freqs$total), ]
return(freqs)
}
freq1 <- findFreq(count.all)
cloud <- wordcloud(freq1$X, freq1$total, scale=c(2.5,0.5), min.freq=100, max.words=200, random.order=FALSE)
#dev.copy(png,'plots/southpark_wordcloud.png')
#dev.off()
